{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入所需要的库（llama_cpp库如果直接安装失败可以尝试下载对应的whl包进行安装，下载地址：https://abetlen.github.io/llama-cpp-python/whl/cpu/llama-cpp-python/ ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地部署大模型：需在huggingface上下载模型文件，下载地址：https://huggingface.co/Triangle104/Qwen2.5-3B-Instruct-abliterated-Q4_K_M-GGUF/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\".\\qwen2.5-3b-instruct-abliterated-q4_k_m.gguf\", verbose=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个模型对话的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southeast University is located in Nanjing, Jiangsu Province, China.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Where is Southeast University located?\"\n",
    "output = llm.create_chat_completion(\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }],\n",
    "    max_tokens=200,\n",
    "    stream=False,\n",
    ")\n",
    "answer = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请比较一下提示词工程对大模型输出的影响,\n",
    "下面是第三次实验的机器翻译任务（可以通过对translate函数进行修改加入一些提示词工程），也可以尝试其他任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(english_sentence):\n",
    "    instruntion = \"Translate the following sentence to Japanese: \"\n",
    "\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruntion+\" \"+english_sentence\n",
    "        }],\n",
    "        max_tokens=200,\n",
    "        stream=False,\n",
    "    )\n",
    "    answer = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: 照顾好自己。\n",
      "candidate: The translated sentence for \"Take care.\" in Japanese is \"お気をください。\" (O kikasueru kudasai. )\n",
      "reference: 在这等着。\n",
      "candidate: The translated sentence for \"Wait here.\" in Japanese is \"ここに待ってください.\" (Koko ni tai sure kudasai. )\n",
      "reference: 做得好！\n",
      "candidate: Well done! 可能な限り日本語で返答しますので、次の質問をお待ちしております。とします。次の質問を待ちます! と訳すと、次の日本語は「次の質問をお待ちしております!」になります。したがって、「Well done!」は「とても良い!」または「素晴らしい!」という意味になります。「とても良い!」の日本語訳は「とても良い!」で、「素晴らしい!」の日本語訳は「素晴らしい!」になります。したがって、「Well done!」の日本語訳は「とても良い!」または「素晴らしい!」になります。\n",
      "reference: 他向我施压。\n",
      "candidate: The translation of \"He pressured me\" to Japanese is \"彼は私を圧迫しました\" (Kare wa watashi o kakushin-shimashita).\n",
      "reference: 他努力學習。\n",
      "candidate: The translated sentence in Japanese is:  他は努力を惜しまなかった。 (Kata wa kouzai o sakina nakatta. )\n",
      "reference: 他企图说谎。\n",
      "candidate: The translated sentence is: 他 tends to lie. (Kano de ta tai ri.)\n",
      "reference: 他很容易觉得累。\n",
      "candidate: The translated sentence for \"He tires easily.\" in Japanese is:\n",
      "\n",
      "「彼は疲れやすいです。」\n",
      "(Kano wa tsuyaku sutari desu.)\n",
      "\n",
      "This can also be expressed as:\n",
      "\n",
      "「彼は疲れやすい。」\n",
      "(Kano wa tsuyaku sutari.)\n",
      "\n",
      "Both of these sentences are correct and convey the same meaning.\n",
      "reference: 他很老。\n",
      "candidate: The translated sentence in Japanese is: 他(彼)は非常に(old)老(お)いて(いた)い(でした)。 (Kare wa kyoo ni oretaiti deshita. )\n",
      "reference: 你有电视吗？\n",
      "candidate: The translated sentence \"Do you have a TV?\" in Japanese is \"テレビがありますか?\" (television ga arimasuka?).\n",
      "reference: 你們有小孩嗎?\n",
      "candidate: The translated sentence for \"Do you have kids?\" in Japanese is:\n",
      "\n",
      "子供がいますか？\n",
      "\n",
      "(Kotoondo ga imasu ka?)\n",
      "\n",
      "This is a standard Japanese question that can be used in a conversation to ask about someone's children.\n",
      "0.00043367609947136097\n"
     ]
    }
   ],
   "source": [
    "chinese_dev_list = []\n",
    "english_dev_list = []\n",
    "with open(\"../exp3/data/dev.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        english,chinese = line.strip().split(\"\\t\")\n",
    "        chinese_dev_list.append(chinese)\n",
    "        english_dev_list.append(english)\n",
    "\n",
    "references = []\n",
    "candidates = []\n",
    "for i in range(10):\n",
    "    e_s = english_dev_list[i]\n",
    "    c_s = chinese_dev_list[i]\n",
    "    answer = translate(e_s)\n",
    "    references.append([c_s])\n",
    "    candidates.append(answer)\n",
    "    print('reference:', c_s)\n",
    "    print('candidate:', answer)\n",
    "    \n",
    "smoothie = SmoothingFunction().method1\n",
    "corpus_score = corpus_bleu(\n",
    "    references,\n",
    "    candidates,\n",
    "    smoothing_function=smoothie\n",
    ")\n",
    "print(corpus_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
