{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入所需要的库（llama_cpp库如果直接安装失败可以尝试下载对应的whl包进行安装，下载地址：https://abetlen.github.io/llama-cpp-python/whl/cpu/llama-cpp-python/ ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本地部署大模型：需在huggingface上下载模型文件，下载地址：https://huggingface.co/Triangle104/Qwen2.5-3B-Instruct-abliterated-Q4_K_M-GGUF/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"D:\\model\\qwen2.5-3b-instruct-q4_k_m\\qwen2.5-3b-instruct-abliterated-q4_k_m.gguf\", verbose=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个模型对话的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southeast University is located in Nanjing, Jiangsu Province, China.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Where is Southeast University located?\"\n",
    "output = llm.create_chat_completion(\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }],\n",
    "    max_tokens=200,\n",
    "    stream=False,\n",
    ")\n",
    "answer = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请比较一下提示词工程对大模型输出的影响,\n",
    "下面是第三次实验的机器翻译任务（可以通过对translate函数进行修改加入一些提示词工程），也可以尝试其他任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(english_sentence):\n",
    "    instruntion = \"please translate the following english sentence to chinese\"\n",
    "\n",
    "    output = llm.create_chat_completion(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruntion+\" \"+english_sentence\n",
    "        }],\n",
    "        max_tokens=200,\n",
    "        stream=False,\n",
    "    )\n",
    "    answer = output[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference 照顾好自己。\n",
      "candidate Take care. 可以翻译成中文是 \"保重。\"\n",
      "reference 在这等着。\n",
      "candidate Wait here. 的中文翻译是 \"等在这里。\"\n",
      "reference 做得好！\n",
      "candidate 非常好！\n",
      "reference 他向我施压。\n",
      "candidate 他壓著我。\n",
      "reference 他努力學習。\n",
      "candidate 他学习很用功。\n",
      "reference 他企图说谎。\n",
      "candidate 他喜欢说谎。\n",
      "reference 他很容易觉得累。\n",
      "candidate 他容易累。\n",
      "reference 他很老。\n",
      "candidate 他非常老。\n",
      "reference 你有电视吗？\n",
      "candidate Do you have a TV? 的中文翻译是 \"您有一台电视吗？\"\n",
      "reference 你們有小孩嗎?\n",
      "candidate Do you have kids? 的中文翻译是 \"您有孩子吗？\"\n",
      "0.041374412020518815\n"
     ]
    }
   ],
   "source": [
    "chinese_dev_list = []\n",
    "english_dev_list = []\n",
    "with open(\"D:/file/file/人工智能概论/code/transformer_trans/data/dev.txt\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        english,chinese = line.strip().split(\"\\t\")\n",
    "        chinese_dev_list.append(chinese)\n",
    "        english_dev_list.append(english)\n",
    "\n",
    "references = []\n",
    "candidates = []\n",
    "for i in range(10):\n",
    "    e_s = english_dev_list[i]\n",
    "    c_s = chinese_dev_list[i]\n",
    "    answer = translate(e_s)\n",
    "    references.append([c_s])\n",
    "    candidates.append(answer)\n",
    "    print('reference:', c_s)\n",
    "    print('candidate:', answer)\n",
    "    \n",
    "smoothie = SmoothingFunction().method1\n",
    "corpus_score = corpus_bleu(\n",
    "    references,\n",
    "    candidates,\n",
    "    smoothing_function=smoothie\n",
    ")\n",
    "print(corpus_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
